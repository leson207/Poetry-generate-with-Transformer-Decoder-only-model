# Poetry-generate-with-Transformer-Decoder-only-model
Poetry generate with Transformer Decoder-only model  
This project experiment causual generated task with poetry on many way:  
  + Transformer decoder-only model form scrath with custom tokenizer (Model folder)  
  + Transformer decoder-only model form scrath with GPT2 tokenizer form HuggingFace  
  + Transformer decoder-only model form scrath with GPT2 tokenizer and Pre-trained Embedding from HuggingFace  
  + Transformer decoder-only model form scrath with GPT2 tokenizer and Pre-trained Embedding from HuggingFace  
  + GPT2 model from scratch from HuggingFace  
  + Fine-tune GPT2 model from HuggingFace  
